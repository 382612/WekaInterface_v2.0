button=Go to page
explorer.info=Explore weka and it's features.
information=What is machine learning?
subtitle=Explore the features of machine learning by using our easy to use interface.
title=Klessify
infopage.basicinfoweka="Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
infopage.title=Weka Algortihms
navbar.about=About
navbar.contact=Contact
navbar.home=Home
student.email=Student email
student.names=Students
title.contact=Contact
subtitle.contact=Meet the team behind our Weka Interface.
marijke.info=The Back End developer, responsible for all the moving parts on the server side that communicates with the HTML pages.
bart.info=Our gitmaster, responsible for version management, making \
sure that working in the same code project runs smoothly.
jelle.info=The Front End developer, creating the HTML pages that you see and\
small functionality on the pages.
michiel.info=The project supervisor, giving advice on how to tackle problems \
and providing sources of information.

ZeroR.information=The simplest of the rule based classifiers is the majority class classifier, called 0-R or\
ZeroR in Weka. The 0-R (zero rule) classifier takes a look at the target attribute and its possible\
values. It will always output the value that is most commonly found for the target attribute in the\
given dataset. 0-R as its names suggests; it does not include any rule that works on the non target\
attributes. So more specifically it predicts the mean (for a numeric type target attribute) or the mode\
(for a nominal type attribute).
OneR.information=This is also another simple rule based classifier. In this case only one rule is applied to the\
dataset, hence called 1R or OneR in Weka. The classifier will select one attribute and find the best\
classification rule based on it. Using the value of this attribute for a given instance, the rule will\
then predict the value of the target attribute. In other words, it uses the minimum-error attribute for\
prediction and discretizing numeric attributes. For more information see:\
R.C. Holte (1993). Very simple classification rules perform well on most commonly used datasets.
NaiveBayes.information=In statistics, naive Bayes classifiers are a family of simple "probabilistic classifiers" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features (see Bayes classifier). They are among the simplest Bayesian network models, but coupled with kernel density estimation, they can achieve higher accuracy levels. Naïve Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. Maximum-likelihood training can be done by evaluating a closed-form expression, which takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers.
IBK.information=In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric classification method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover. It is used for classification and regression. In both cases, the input consists of the k closest training examples in data set. The output depends on whether k-NN is used for classification or regression:\
\
In k-NN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor.
J48.information=J4.8 is Weka implementation of decision tree algorithm C4.5. It is actually built upon ID3\
algorithm by adding features like pruning as well as allowing numeric attribute values.\
C4.5 is an algorithm used to generate a decision tree developed by Ross Quinlan. C4.5 is an extension of Quinlan's earlier ID3 algorithm. The decision trees generated by C4.5 can be used for classification, and for this reason, C4.5 is often referred to as a statistical classifier. In 2011, authors of the Weka machine learning software described the C4.5 algorithm as "a landmark decision tree program that is probably the machine learning workhorse most widely used in practice to date"
WekaAlgorithms.information="Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."

results.title=Results
form.select=Select the demo file: 
form.upload=Or upload your own file:
form.choose=Choose file
form.classifier.select=Select the classifier:
max.batchsize.explaination=
debug.par.explaination=
doNotCheck.par.explaination=
num.decimal.explaination=
true=Yes
false=No
max.batchsize=Maximum Batchsize
debug.par=Debug
doNotCheck.par=Do not check capabilities
num.decimal.par=Number of decimal places
minBucketSize.par=Minimum bucketsize
confidenceFactor.par=Confidence factor
minNumObj.par=Minimum number of objects
numFold.par=Number of folds
laPlace.par=la Place estimator
pruned.par=Pruned
knn.par=K-nearest neighbour
crossValidate.par=Crossvalidate
nnsearchAlgorithm.par=Nearest neighbour \
search algorithm
results.title=Results
form.file.select=Select...
information.title=Weka Algortihms
button.return=Return


